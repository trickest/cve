### [CVE-2024-41130](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2024-41130)
![](https://img.shields.io/static/v1?label=Product&message=llama.cpp&color=blue)
![](https://img.shields.io/static/v1?label=Version&message=%3C%20b3427%20&color=brightgreen)
![](https://img.shields.io/static/v1?label=Version&message=0%20&color=brightgreen)
![](https://img.shields.io/static/v1?label=Vulnerability&message=CWE-476%3A%20NULL%20Pointer%20Dereference&color=brightgreen)

### Description

llama.cpp provides LLM inference in C/C++. Prior to b3427, llama.cpp contains a null pointer dereference in gguf_init_from_file. This vulnerability is fixed in b3427.

### POC

#### Reference
- https://github.com/ggerganov/llama.cpp/security/advisories/GHSA-49q7-2jmh-92fp

#### Github
No PoCs found on GitHub currently.

