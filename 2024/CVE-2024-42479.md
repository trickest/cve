### [CVE-2024-42479](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2024-42479)
![](https://img.shields.io/static/v1?label=Product&message=llama.cpp&color=blue)
![](https://img.shields.io/static/v1?label=Version&message=%3C%20b3561%20&color=brightgreen)
![](https://img.shields.io/static/v1?label=Version&message=0%20&color=brightgreen)
![](https://img.shields.io/static/v1?label=Vulnerability&message=CWE-123%3A%20Write-what-where%20Condition&color=brightgreen)

### Description

llama.cpp provides LLM inference in C/C++. The unsafe `data` pointer member in the `rpc_tensor` structure can cause arbitrary address writing. This vulnerability is fixed in b3561.

### POC

#### Reference
- https://github.com/ggerganov/llama.cpp/commit/b72942fac998672a79a1ae3c03b340f7e629980b
- https://github.com/ggerganov/llama.cpp/security/advisories/GHSA-wcr5-566p-9cwj

#### Github
- https://github.com/7resp4ss/7resp4ss
- https://github.com/fkie-cad/nvd-json-data-feeds
- https://github.com/honysyang/eleaipoc

