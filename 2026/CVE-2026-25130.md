### [CVE-2026-25130](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2026-25130)
![](https://img.shields.io/static/v1?label=Product&message=cai&color=blue)
![](https://img.shields.io/static/v1?label=Version&message=%3C%3D%200.5.10%20&color=brightgreen)
![](https://img.shields.io/static/v1?label=Vulnerability&message=CWE-78%3A%20Improper%20Neutralization%20of%20Special%20Elements%20used%20in%20an%20OS%20Command%20('OS%20Command%20Injection')&color=brightgreen)

### Description

Cybersecurity AI (CAI) is a framework for AI Security. In versions up to and including 0.5.10, the CAI (Cybersecurity AI) framework contains multiple argument injection vulnerabilities in its function tools. User-controlled input is passed directly to shell commands via `subprocess.Popen()` with `shell=True`, allowing attackers to execute arbitrary commands on the host system. The `find_file()` tool executes without requiring user approval because find is considered a "safe" pre-approved command. This means an attacker can achieve Remote Code Execution (RCE) by injecting malicious arguments (like -exec) into the args parameter, completely bypassing any human-in-the-loop safety mechanisms. Commit e22a1220f764e2d7cf9da6d6144926f53ca01cde contains a fix.

### POC

#### Reference
- https://github.com/aliasrobotics/cai/security/advisories/GHSA-jfpc-wj3m-qw2m

#### Github
No PoCs found on GitHub currently.

