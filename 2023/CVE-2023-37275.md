### [CVE-2023-37275](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-37275)
![](https://img.shields.io/static/v1?label=Product&message=Auto-GPT&color=blue)
![](https://img.shields.io/static/v1?label=Version&message=%3C%200.4.3%20&color=brightgreen)
![](https://img.shields.io/static/v1?label=Vulnerability&message=CWE-117%3A%20Improper%20Output%20Neutralization%20for%20Logs&color=brightgreen)

### Description

Auto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model. The Auto-GPT command line UI makes heavy use of color-coded print statements to signify different types of system messages to the user, including messages that are crucial for the user to review and control which commands should be executed. Before v0.4.3, it was possible for a malicious external resource (such as a website browsed by Auto-GPT) to cause misleading messages to be printed to the console by getting the LLM to regurgitate JSON encoded ANSI escape sequences (`\u001b[`). These escape sequences were JSON decoded and printed to the console as part of the model's "thinking process". The issue has been patched in release version 0.4.3.

### POC

#### Reference
No PoCs from references.

#### Github
- https://github.com/fkie-cad/nvd-json-data-feeds

